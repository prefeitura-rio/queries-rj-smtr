# Queries SMTR üöçüîé

> Reposit√≥rio adaptado do template do [Escrit√≥rio de
> Dados](https://github.com/prefeitura-rio/queries) para versionamento e
> execu√ß√£o de projetos no datalake.

## Requerimentos

* Python <=3.9

## Desenvolvimento (local)

### Iniciando o ambiente

* Crie um ambiente virtual e instale as depend√™ncias:

```bash
python -m venv dbt-env
. dbt-env/Scripts/activate
python -m pip install --upgrade pip 
pip install -r requirements-dev.txt
```

* Configure suas credenciais para leitura/escrita no datalake:

```bash
# copie o arquivo de exemplo
cp dev/profiles-example.yml dev/profiles.yml
# preencha com suas credenciais
```

* Edite o arquivo [`dev/run.py`](dev/run.py) para rodar seus testes. Em
  seguida, execute o script:

```bash
python dev/run.py
```

## Adicionando dados

### Novo conjunto

1. Crie uma branch com o mesmo padr√£o da pipeline correspondente em
   [pipelines](https://github.com/prefeitura/pipelines)(quando houver)

2. Crie um novo diret√≥rio `models/<dataset-id>`, sendo `dataset_id` o
   nome do conjunto. Nesta pasta ser√£o guardadas as queries (modelos) que d√£o
   origem √†s tabelas deste dataset no BigQuery.

3. No arquivo `dbt_project.yml`, adicione o `dataset-id` junto aos
   conjuntos j√° registrados, conforme abaixo:

```yaml
models:
  rj-smtr:
    <dataset-id>:
      +materialized: view # Materialization type (view, table or incremental)
      +schema: <dataset-id> # Overrides the default schema (defaults to what is set on profiles.yml)
```

### Novas tabelas

Crie os modelos que desejar em `models/<dataset-id>` (ex:
`nome_da_tabela.sql`). Nesses arquivos, adicione o c√≥digo SQL utilizado
para gerar as tabelas no BigQuery. Quaisquer especifica√ß√µes de particionamento
tamb√©m devem ser inseridas ali.

Leia:

* [Tipos de tabela do dbt](https://docs.getdbt.com/docs/build/materializations)
* [Configura√ß√µes de particionamento no dbt](https://docs.getdbt.com/reference/resource-configs/bigquery-configs)

#### Para publicar no datario

**Antes de fazer o merge da branch, garanta que os devidos metadados
para a(s) nova(s) tabela(s) est√£o preenchidos no portal
<https://meta.dados.rio/>**. Caso ontr√°rio, n√£o ser√° gerada a documenta√ß√£o
da tabela.
